{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "1.18.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 335.280823 |    -4.0663 |     1.1220 |  -6.065215\n",
      "   50 |  76.037262 |    -0.8001 |     1.6209 |  -4.978779\n",
      "  100 |  18.959263 |     0.7151 |     1.8781 |  -4.429109\n",
      "  150 |   6.310240 |     1.4125 |     2.0104 |  -4.134423\n",
      "  200 |   3.445082 |     1.7284 |     2.0768 |  -3.961648\n",
      "  250 |   2.743659 |     1.8667 |     2.1075 |  -3.847750\n",
      "  300 |   2.525401 |     1.9225 |     2.1184 |  -3.762738\n",
      "  350 |   2.417754 |     1.9402 |     2.1181 |  -3.692262\n",
      "  400 |   2.337300 |     1.9403 |     2.1114 |  -3.629400\n",
      "  450 |   2.264998 |     1.9325 |     2.1008 |  -3.570778\n",
      "  500 |   2.196328 |     1.9213 |     2.0881 |  -3.514729\n",
      "  550 |   2.130126 |     1.9085 |     2.0741 |  -3.460409\n",
      "  600 |   2.066037 |     1.8953 |     2.0595 |  -3.407385\n",
      "  650 |   2.003917 |     1.8819 |     2.0444 |  -3.355424\n",
      "  700 |   1.943679 |     1.8686 |     2.0293 |  -3.304398\n",
      "  750 |   1.885258 |     1.8555 |     2.0141 |  -3.254230\n",
      "  800 |   1.828595 |     1.8425 |     1.9990 |  -3.204873\n",
      "  850 |   1.773636 |     1.8297 |     1.9841 |  -3.156293\n",
      "  900 |   1.720329 |     1.8171 |     1.9693 |  -3.108468\n",
      "  950 |   1.668625 |     1.8048 |     1.9547 |  -3.061379\n",
      " 1000 |   1.618474 |     1.7926 |     1.9403 |  -3.015011\n"
     ]
    }
   ],
   "source": [
    "x1_data = [1, 0, 3, 0, 5]\n",
    "x2_data = [0, 2, 0, 4, 0]\n",
    "y_data = [1, 2, 3, 4, 5]\n",
    "\n",
    "W1 = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "W2 = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "b = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "\n",
    "learning_rate = tf.Variable(0.001)\n",
    "\n",
    "for i in range(1000 + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypo = W1 * x1_data + W2 * x2_data + b\n",
    "        cost = tf.reduce_mean(tf.square(hypo - y_data))\n",
    "    W1_grad, W2_grad, b_grad = tape.gradient(cost, [W1, W2, b])\n",
    "    W1.assign_sub(learning_rate * W1_grad)\n",
    "    W2.assign_sub(learning_rate * W2_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "         print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\n",
    "          i, cost.numpy(), W1.numpy()[0], W2.numpy()[0], b.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |  25.972300 |    -0.9515 |     0.0227 |   0.600074\n",
      "   50 |   6.070779 |    -0.0653 |     0.2696 |   0.888581\n",
      "  100 |   1.597466 |     0.3474 |     0.4153 |   1.021349\n",
      "  150 |   0.567457 |     0.5400 |     0.5039 |   1.078805\n",
      "  200 |   0.317824 |     0.6306 |     0.5597 |   1.099501\n",
      "  250 |   0.250031 |     0.6742 |     0.5960 |   1.102061\n",
      "  300 |   0.226705 |     0.6960 |     0.6205 |   1.095580\n",
      "  350 |   0.215147 |     0.7080 |     0.6379 |   1.084555\n",
      "  400 |   0.207104 |     0.7156 |     0.6507 |   1.071247\n",
      "  450 |   0.200309 |     0.7211 |     0.6607 |   1.056813\n",
      "  500 |   0.194068 |     0.7258 |     0.6688 |   1.041862\n",
      "  550 |   0.188148 |     0.7301 |     0.6758 |   1.026716\n",
      "  600 |   0.182457 |     0.7341 |     0.6819 |   1.011554\n",
      "  650 |   0.176958 |     0.7381 |     0.6875 |   0.996476\n",
      "  700 |   0.171634 |     0.7420 |     0.6928 |   0.981537\n",
      "  750 |   0.166473 |     0.7459 |     0.6978 |   0.966768\n",
      "  800 |   0.161468 |     0.7497 |     0.7026 |   0.952189\n",
      "  850 |   0.156615 |     0.7535 |     0.7072 |   0.937810\n",
      "  900 |   0.151908 |     0.7572 |     0.7117 |   0.923634\n",
      "  950 |   0.147342 |     0.7609 |     0.7162 |   0.909664\n",
      " 1000 |   0.142913 |     0.7645 |     0.7205 |   0.895900\n"
     ]
    }
   ],
   "source": [
    "x_data = [\n",
    "    [1., 0., 3., 0., 5.],\n",
    "    [0., 2., 0., 4., 0.]\n",
    "]\n",
    "y_data = [1, 2, 3, 4, 5]\n",
    "\n",
    "W = tf.Variable(tf.random.uniform((1,2), -1.0, 1.0))\n",
    "b = tf.Variable(tf.random.uniform((1,), -1.0, 1.0))\n",
    "\n",
    "learning_rate = tf.Variable(0.001)\n",
    "\n",
    "for i in range(1000 + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypo = tf.matmul(W, x_data) + b\n",
    "        cost = tf.reduce_mean(tf.square(hypo - y_data))\n",
    "        \n",
    "        W_grad, b_grad = tape.gradient(cost, [W,b])\n",
    "        W.assign_sub(learning_rate * W_grad)\n",
    "        b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\n",
    "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |  20.821461 |    -0.9113 |    -0.3731 |     0.5707\n",
      "   50 |   4.728793 |    -0.6296 |     0.4178 |     0.7869\n",
      "  100 |   1.114711 |    -0.4884 |     0.7831 |     0.9118\n",
      "  150 |   0.286174 |    -0.4154 |     0.9507 |     0.9852\n",
      "  200 |   0.089094 |    -0.3757 |     1.0266 |     1.0291\n",
      "  250 |   0.039149 |    -0.3527 |     1.0602 |     1.0555\n",
      "  300 |   0.025114 |    -0.3382 |     1.0745 |     1.0713\n",
      "  350 |   0.020492 |    -0.3280 |     1.0801 |     1.0807\n",
      "  400 |   0.018589 |    -0.3202 |     1.0817 |     1.0862\n",
      "  450 |   0.017563 |    -0.3138 |     1.0815 |     1.0891\n",
      "  500 |   0.016855 |    -0.3081 |     1.0807 |     1.0905\n",
      "  550 |   0.016276 |    -0.3028 |     1.0796 |     1.0908\n",
      "  600 |   0.015758 |    -0.2979 |     1.0784 |     1.0906\n",
      "  650 |   0.015272 |    -0.2932 |     1.0771 |     1.0899\n",
      "  700 |   0.014808 |    -0.2886 |     1.0759 |     1.0890\n",
      "  750 |   0.014360 |    -0.2841 |     1.0747 |     1.0880\n",
      "  800 |   0.013928 |    -0.2798 |     1.0736 |     1.0869\n",
      "  850 |   0.013509 |    -0.2755 |     1.0724 |     1.0857\n",
      "  900 |   0.013103 |    -0.2713 |     1.0713 |     1.0845\n",
      "  950 |   0.012709 |    -0.2672 |     1.0702 |     1.0832\n",
      " 1000 |   0.012327 |    -0.2631 |     1.0692 |     1.0820\n"
     ]
    }
   ],
   "source": [
    "#bias 추가\n",
    "x_data = [\n",
    "    [1., 1., 1., 1., 1.],\n",
    "    [1., 0., 3., 0., 5.],\n",
    "    [0., 2., 0., 4., 0.]\n",
    "]\n",
    "y_data = [1, 2, 3, 4, 5]\n",
    "\n",
    "#bias 삭제\n",
    "W = tf.Variable(tf.random.uniform((1, 3), -1.0, 1.0))\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "for i in range(1000 + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypo = tf.matmul(W, x_data)\n",
    "        cost = tf.reduce_mean(tf.square(hypo - y_data))\n",
    "    grads = tape.gradient(cost, [W])\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W]))\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.4f}\".format(\n",
    "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], W.numpy()[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    0 |   7.591746\n",
      "   50 |   0.061465\n",
      "  100 |   0.042024\n",
      "  150 |   0.028732\n",
      "  200 |   0.019645\n",
      "  250 |   0.013431\n",
      "  300 |   0.009183\n",
      "  350 |   0.006278\n",
      "  400 |   0.004293\n",
      "  450 |   0.002935\n",
      "  500 |   0.002007\n",
      "  550 |   0.001372\n",
      "  600 |   0.000938\n",
      "  650 |   0.000641\n",
      "  700 |   0.000438\n",
      "  750 |   0.000300\n",
      "  800 |   0.000205\n",
      "  850 |   0.000140\n",
      "  900 |   0.000096\n",
      "  950 |   0.000066\n",
      " 1000 |   0.000045\n"
     ]
    }
   ],
   "source": [
    "#bias없이, optimizer 사용\n",
    "\n",
    "X = tf.constant([[1., 2.], [3., 4.]])\n",
    "y = tf.constant([[1.5], [3.5]])\n",
    "\n",
    "W = tf.Variable(tf.random.normal((2, 1)))\n",
    "b = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "n_epoch = 1000 + 1\n",
    "print(\"epoch | cost\")\n",
    "for i in range(n_epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypo = tf.matmul(X, W) + b\n",
    "        cost = tf.reduce_mean(tf.square(hypo - y))\n",
    "    grads = tape.gradient(cost, [W, b])\n",
    "    #W, b update\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |   11325.9121\n",
      "   50 |     135.3618\n",
      "  100 |      11.1817\n",
      "  150 |       9.7940\n",
      "  200 |       9.7687\n",
      "  250 |       9.7587\n",
      "  300 |       9.7489\n",
      "  350 |       9.7389\n",
      "  400 |       9.7292\n",
      "  450 |       9.7194\n",
      "  500 |       9.7096\n",
      "  550 |       9.6999\n",
      "  600 |       9.6903\n",
      "  650 |       9.6806\n",
      "  700 |       9.6709\n",
      "  750 |       9.6612\n",
      "  800 |       9.6517\n",
      "  850 |       9.6421\n",
      "  900 |       9.6325\n",
      "  950 |       9.6229\n",
      " 1000 |       9.6134\n"
     ]
    }
   ],
   "source": [
    "#matrix 없이 예측\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "x1 = [ 73.,  93.,  89.,  96.,  73.]\n",
    "x2 = [ 80.,  88.,  91.,  98.,  66.]\n",
    "x3 = [ 75.,  93.,  90., 100.,  70.]\n",
    "Y  = [152., 185., 180., 196., 142.]\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal((1,)))\n",
    "w2 = tf.Variable(tf.random.normal((1,)))\n",
    "w3 = tf.Variable(tf.random.normal((1,)))\n",
    "b  = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "for i in range(1000 + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypo = w1 * x1 + w2 * x2 + w3 *x3 + b\n",
    "        cost = tf.reduce_mean(tf.square(hypo - Y))\n",
    "        w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])\n",
    "        \n",
    "    w1.assign_sub(learning_rate * w1_grad)\n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:12.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    0 |  9563.7852\n",
      "  100 |     4.5003\n",
      "  200 |     3.3124\n",
      "  300 |     3.3014\n",
      "  400 |     3.2907\n",
      "  500 |     3.2800\n",
      "  600 |     3.2693\n",
      "  700 |     3.2587\n",
      "  800 |     3.2482\n",
      "  900 |     3.2378\n",
      " 1000 |     3.2274\n"
     ]
    }
   ],
   "source": [
    "#matrix를 사용하여 예측\n",
    "\n",
    "data = np.array([\n",
    "    # X1,   X2,    X3,   y\n",
    "    [ 73.,  80.,  75., 152. ],\n",
    "    [ 93.,  88.,  93., 185. ],\n",
    "    [ 89.,  91.,  90., 180. ],\n",
    "    [ 96.,  98., 100., 196. ],\n",
    "    [ 73.,  66.,  70., 142. ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "#slicing으로 x, y를 분리\n",
    "#[행, 열]\n",
    "X = data[:, :-1]\n",
    "y = data[:, [-1]]\n",
    "\n",
    "W = tf.Variable(tf.random.normal((3, 1)))\n",
    "b = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "#hypothesis\n",
    "def predict(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "print(\"epoch | cost\")\n",
    "\n",
    "n_epochs = 2000\n",
    "for i in range(n_epoch + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean((tf.square(predict(X) - y)))\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "     \n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"{:5} | {:10.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8618126 ],\n",
       "       [ 0.53110343],\n",
       "       [-0.36347008]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.57494545], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152.],\n",
       "       [185.],\n",
       "       [180.],\n",
       "       [196.],\n",
       "       [142.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[182.14197],\n",
       "       [173.78386]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict([[ 89.,  95.,  92.],[ 84.,  92.,  85.]]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
