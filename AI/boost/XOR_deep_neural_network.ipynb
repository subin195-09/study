{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data 그래프로 표현\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "\n",
    "plt.scatter(x_data[0][0],x_data[0][1], c='red' , marker='^')\n",
    "plt.scatter(x_data[3][0],x_data[3][1], c='red' , marker='^')\n",
    "plt.scatter(x_data[1][0],x_data[1][1], c='blue' , marker='^')\n",
    "plt.scatter(x_data[2][0],x_data[2][1], c='blue' , marker='^')\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시킬 데이터를 dataset에 담은 후 batch size를 정한다\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(len(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4layer로 deep nn model을 만든다\n",
    "nb_classes = 10\n",
    "\n",
    "class wide_deep_nn():\n",
    "    def __init__(self, nb_classes):\n",
    "        super(wide_deep_nn, self).__init__()        \n",
    "     \n",
    "        self.W1 = tf.Variable(tf.random.normal((2, nb_classes)), name='weight1')\n",
    "        self.b1 = tf.Variable(tf.random.normal((nb_classes,)), name='bias1')\n",
    "\n",
    "        self.W2 = tf.Variable(tf.random.normal((nb_classes, nb_classes)), name='weight2')\n",
    "        self.b2 = tf.Variable(tf.random.normal((nb_classes,)), name='bias2')\n",
    "\n",
    "        self.W3 = tf.Variable(tf.random.normal((nb_classes, nb_classes)), name='weight3')\n",
    "        self.b3 = tf.Variable(tf.random.normal((nb_classes,)), name='bias3')\n",
    "\n",
    "        self.W4 = tf.Variable(tf.random.normal((nb_classes, 1)), name='weight4')\n",
    "        self.b4 = tf.Variable(tf.random.normal((1,)), name='bias4')\n",
    "        \n",
    "        self.variables = [self.W1,self.b1,self.W2,self.b2,self.W3,self.b3,self.W4,self.b4]\n",
    "    \n",
    "    # 학습 시킬 데이터 casting\n",
    "    def preprocess_data(self, features, labels):\n",
    "        features = tf.cast(features, tf.float32)\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "        return features, labels\n",
    "    \n",
    "    def deep_nn(self, features):\n",
    "            layer1 = tf.sigmoid(tf.matmul(features, self.W1) + self.b1)\n",
    "            layer2 = tf.sigmoid(tf.matmul(layer1, self.W2) + self.b2)\n",
    "            layer3 = tf.sigmoid(tf.matmul(layer2, self.W3) + self.b3)\n",
    "            hypothesis = tf.sigmoid(tf.matmul(layer3, self.W4) + self.b4)\n",
    "            return hypothesis\n",
    "    # cost function\n",
    "    def loss_fn(self, hypothesis, features, labels):\n",
    "        cost = -tf.reduce_mean(labels * tf.math.log(hypothesis) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
    "        return cost\n",
    "    # 0.5 기준으로 0 or 1\n",
    "    def accuracy_fn(self, hypothesis, labels):\n",
    "        predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
    "        return accuracy\n",
    "\n",
    "    def grad(self, hypothesis, features, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = self.loss_fn(self.deep_nn(features),features,labels)\n",
    "        return tape.gradient(loss_value,self.variables)\n",
    "    \n",
    "    # 학습 \n",
    "    def fit(self, dataset, EPOCHS=20000, verbose=500):\n",
    "        optimizer =  tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "        for step in range(EPOCHS):\n",
    "            for features, labels  in dataset:\n",
    "                features, labels = self.preprocess_data(features, labels)\n",
    "                grads = self.grad(self.deep_nn(features), features, labels)\n",
    "                optimizer.apply_gradients(grads_and_vars=zip(grads, self.variables))\n",
    "                if step % verbose == 0:\n",
    "                    print(\"Iter: {}, Loss: {:.4f}\".format(step, self.loss_fn(self.deep_nn(features),features,labels)))\n",
    "\n",
    "    # 학습된 model로 test 해보기\n",
    "    def test_model(self,x_data, y_data):\n",
    "        x_data, y_data = self.preprocess_data(x_data, y_data)\n",
    "        test_acc = self.accuracy_fn(self.deep_nn(x_data),y_data)\n",
    "        print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 0.7044\n",
      "Iter: 500, Loss: 0.6894\n",
      "Iter: 1000, Loss: 0.6870\n",
      "Iter: 1500, Loss: 0.6843\n",
      "Iter: 2000, Loss: 0.6812\n",
      "Iter: 2500, Loss: 0.6776\n",
      "Iter: 3000, Loss: 0.6733\n",
      "Iter: 3500, Loss: 0.6679\n",
      "Iter: 4000, Loss: 0.6612\n",
      "Iter: 4500, Loss: 0.6527\n",
      "Iter: 5000, Loss: 0.6418\n",
      "Iter: 5500, Loss: 0.6281\n",
      "Iter: 6000, Loss: 0.6108\n",
      "Iter: 6500, Loss: 0.5895\n",
      "Iter: 7000, Loss: 0.5635\n",
      "Iter: 7500, Loss: 0.5322\n",
      "Iter: 8000, Loss: 0.4953\n",
      "Iter: 8500, Loss: 0.4531\n",
      "Iter: 9000, Loss: 0.4073\n",
      "Iter: 9500, Loss: 0.3603\n",
      "Iter: 10000, Loss: 0.3147\n",
      "Iter: 10500, Loss: 0.2728\n",
      "Iter: 11000, Loss: 0.2357\n",
      "Iter: 11500, Loss: 0.2038\n",
      "Iter: 12000, Loss: 0.1767\n",
      "Iter: 12500, Loss: 0.1539\n",
      "Iter: 13000, Loss: 0.1348\n",
      "Iter: 13500, Loss: 0.1186\n",
      "Iter: 14000, Loss: 0.1048\n",
      "Iter: 14500, Loss: 0.0932\n",
      "Iter: 15000, Loss: 0.0832\n",
      "Iter: 15500, Loss: 0.0746\n",
      "Iter: 16000, Loss: 0.0672\n",
      "Iter: 16500, Loss: 0.0608\n",
      "Iter: 17000, Loss: 0.0552\n",
      "Iter: 17500, Loss: 0.0503\n",
      "Iter: 18000, Loss: 0.0461\n",
      "Iter: 18500, Loss: 0.0423\n",
      "Iter: 19000, Loss: 0.0390\n",
      "Iter: 19500, Loss: 0.0361\n",
      "Testset Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# model 생성\n",
    "model = wide_deep_nn(nb_classes)\n",
    "\n",
    "# model 학습\n",
    "model.fit(dataset)\n",
    "\n",
    "# model test\n",
    "model.test_model(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
